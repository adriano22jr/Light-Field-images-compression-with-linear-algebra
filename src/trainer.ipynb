{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHAGf6XI6FoL",
        "outputId": "e4223c0e-8eb5-4f0f-cdf0-d0bd06fdc7df"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2Si4qE7I53H_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emNtdbYEKQ57",
        "outputId": "477f0d7c-88c4-4db8-9447-79018dbc67ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 480 images belonging to 1 classes.\n",
            "Found 59 images belonging to 1 classes.\n",
            "Found 67 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = \"/workspace/cnn/nn_datasets/train/\"\n",
        "val_dir = \"/workspace/cnn/nn_datasets/val/\"\n",
        "test_dir = \"/workspace/cnn/nn_datasets/test/\"\n",
        "\n",
        "image_size = (720, 960)\n",
        "batch_size = 2\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'input',\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'input',\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'input',\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KOakF-kO_3AR"
      },
      "outputs": [],
      "source": [
        "class PredictionCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, validation_generator, num_examples=2):\n",
        "        super().__init__()\n",
        "        self.validation_generator = validation_generator\n",
        "        self.num_examples = num_examples\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        x_val, _ = next(self.validation_generator)\n",
        "\n",
        "        predictions = self.model.predict(x_val, verbose=0)\n",
        "\n",
        "        for i in range(self.num_examples):\n",
        "            plt.figure(figsize=(12, 4))\n",
        "\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(x_val[i])\n",
        "            plt.title(\"Input Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(x_val[i])\n",
        "            plt.title(\"Ground Truth\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(predictions[i])\n",
        "            plt.title(\"Reconstructed Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "76oSfb7NB2IQ"
      },
      "outputs": [],
      "source": [
        "class PeriodicCheckpoint(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, filepath, save_freq):\n",
        "        super().__init__()\n",
        "        self.filepath = filepath\n",
        "        self.save_freq = save_freq\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.save_freq == 0:\n",
        "            self.model.save(self.filepath.format(epoch=epoch + 1))\n",
        "            print(f\"Checkpoint saved at epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "9wBOBsGQQr77",
        "outputId": "6af9dc74-52d2-410d-8626-52648e6a2bd9"
      },
      "outputs": [],
      "source": [
        "input_shape = (image_size[0], image_size[1], 3)\n",
        "input_img = layers.Input(shape=input_shape)\n",
        "\n",
        "x = layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding = 'same')(x)\n",
        "x = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding = 'same')(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding = 'same')(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "encoded = layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "\n",
        "x = layers.UpSampling2D((2, 2))(encoded)\n",
        "x = layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same')(x)\n",
        "decoded = layers.Conv2D(3, (3, 3), activation = 'sigmoid', padding = 'same')(x)\n",
        "\n",
        "# autoencoder = models.Model(input_img, decoded)\n",
        "autoencoder = load_model('drive/MyDrive/Colab Notebooks/Colab Notebooks/checkpoints2/autoencoder_epoch_09.h5')\n",
        "autoencoder.compile(optimizer = 'AdamW', loss = 'mean_squared_error')\n",
        "checkpoint_callback = PeriodicCheckpoint(\n",
        "    filepath='drive/MyDrive/Colab Notebooks/Colab Notebooks/checkpoints2/autoencoder_epoch_{epoch:02d}.h5',\n",
        "    save_freq=1\n",
        ")\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlnAD4WEAD-n"
      },
      "outputs": [],
      "source": [
        "prediction_callback = PredictionCallback(test_generator, num_examples=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NV4ahXcc53IF",
        "outputId": "03e92b19-0e85-478c-b255-e29651f32cc3"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(\n",
        "    train_generator,\n",
        "    epochs = 15,\n",
        "    callbacks = [checkpoint_callback, prediction_callback],\n",
        "    validation_data = validation_generator,\n",
        "    verbose = 1,\n",
        ")\n",
        "\n",
        "plt.plot(history.history['loss'], label = 'train')\n",
        "plt.plot(history.history['val_loss'], label = 'val')\n",
        "plt.title('Loss durante l\\'addestramento')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dati estratti dal file\n",
        "epochs = list(range(1, 31))  # Epoch da 1 a 30\n",
        "loss = [\n",
        "    0.0449, 0.0074, 0.0046, 0.0036, 0.0032, 0.0049, 0.0228, 0.0072, 0.0112, 0.0083, \n",
        "    0.0096, 0.0057, 0.0074, 0.0038, 0.0031, 0.0030, 0.0025, 0.0024, 0.0022, 0.0025,\n",
        "    0.0022, 0.0019, 0.0020, 0.0018, 0.0018, 0.0053, 0.0063, 0.0081, 0.0039, 0.0031\n",
        "]\n",
        "val_loss = [\n",
        "    0.0075, 0.0056, 0.0037, 0.0032, 0.0027, 0.0366, 0.0069, 0.0088, 0.0047, 0.0054,\n",
        "    0.0061, 0.0054, 0.0037, 0.0030, 0.0034, 0.0026, 0.0022, 0.0021, 0.0021, 0.0020,\n",
        "    0.0020, 0.0017, 0.0018, 0.0019, 0.0074, 0.0067, 0.0115, 0.0041, 0.0031, 0.0028\n",
        "]\n",
        "\n",
        "# Creazione del plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss, label='Training Loss', marker='o', color='blue')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', marker='s', color='orange')\n",
        "\n",
        "# Configurazioni del grafico\n",
        "plt.title('Andamento della Loss durante l\\'Addestramento', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.xticks(epochs)\n",
        "plt.legend(fontsize=12)\n",
        "\n",
        "# Visualizzazione\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compressione immagini di test per ogni epoch\n",
        "\n",
        "models_dir = '/workspace/cnn/checkpoints'\n",
        "output_dir = '/workspace/results/cnn/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def process_images(model, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    c = 0\n",
        "    while c < 67:\n",
        "        batch = next(test_generator)\n",
        "        decoded_images = model.predict(batch[0])\n",
        "        n = len(decoded_images)\n",
        "        \n",
        "        for i in range(n):\n",
        "            plt.imshow(decoded_images[i])\n",
        "            plt.axis(\"off\")\n",
        "            img_name = f'decoded_{c}.png'\n",
        "            output_path = os.path.join(output_dir, img_name)\n",
        "            plt.savefig(output_path, transparent=True, bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "            \n",
        "            decoded_image = Image.open(output_path)\n",
        "            if decoded_image.size != (960, 720):\n",
        "                print(\"Resizing image...\")\n",
        "                decoded_image = decoded_image.resize((960, 720))\n",
        "                decoded_image.save(output_path)\n",
        "            \n",
        "            c += 1\n",
        "\n",
        "    \n",
        "for epoch in range(1, 31):\n",
        "    model_path = os.path.join(models_dir, f'autoencoder_epoch_{epoch:02d}.h5')\n",
        "    model_output_dir = os.path.join(output_dir, f'epoch_{epoch:02d}')\n",
        "    if os.path.exists(model_path):\n",
        "        model = load_model(model_path)\n",
        "        print(f\"Model for epoch {epoch} loaded.\")\n",
        "        \n",
        "        process_images(model, model_output_dir)\n",
        "    else:\n",
        "        print(f'Model for epoch {epoch} not found.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, re\n",
        "\n",
        "def calculate_metrics(decompressed_path, original_path):  \n",
        "    # Esegui il comando per calcolare SSIM usando ffmpeg\n",
        "    ssim_result = subprocess.run(\n",
        "        [\"../../bin/ffmpeg\", \"-i\", decompressed_path, \"-i\", original_path, \"-lavfi\", \"ssim=stats_file=ssim_logfile.txt\", \"-f\", \"null\", \"-\"],\n",
        "        capture_output = True, text = True\n",
        "    )\n",
        "    \n",
        "    # Esegui il comando per calcolare PSNR usando ffmpeg\n",
        "    psnr_result = subprocess.run(\n",
        "        [\"../../bin/ffmpeg\", \"-i\", decompressed_path, \"-i\", original_path, \"-lavfi\", \"psnr=stats_file=psnr_logfile.txt\", \"-f\", \"null\", \"-\"],\n",
        "        capture_output = True, text = True\n",
        "    )\n",
        "    \n",
        "    # Estrai il valore SSIM dal log\n",
        "    ssim_match = re.search(r\"All:([\\d.]+)\", ssim_result.stderr)\n",
        "    ssim = float(ssim_match.group(1)) if ssim_match else None\n",
        "\n",
        "    # Estrai il valore PSNR medio dal log\n",
        "    psnr_match = re.search(r\"average:([\\d.]+)\", psnr_result.stderr)\n",
        "    #print(psnr_result.stderr)\n",
        "    psnr = float(psnr_match.group(1)) if psnr_match else None\n",
        "    \n",
        "    return ssim, psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing e calcolo metriche PSNR e SSIM\n",
        "\n",
        "test_images_dir = \"/workspace/cnn/nn_datasets/test/images\"\n",
        "results_dir = \"/workspace/results/cnn\"\n",
        "\n",
        "ssim_scores, psnr_scores = [], []\n",
        "for epoch in range(1, 31):\n",
        "    epoch_dir = os.path.join(results_dir, f'epoch_{epoch:02d}')\n",
        "    if os.path.exists(epoch_dir):\n",
        "        ssim, psnr = calculate_metrics(os.path.join(epoch_dir, 'decoded_0.png'), os.path.join(test_images_dir, 'original_0.png'))\n",
        "    \n",
        "        ssim_scores.append(ssim)\n",
        "        psnr_scores.append(psnr)\n",
        "    else:\n",
        "        print(f\"Results for epoch {epoch} not found.\")\n",
        "        \n",
        "print(\"SSIM scores:\", ssim_scores)\n",
        "print(\"PSNR scores:\", psnr_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data\n",
        "epochs = list(range(1, 31))\n",
        "ssim_scores = [0.807223, 0.808263, 0.837779, 0.846401, 0.857456, 0.768931, 0.808735, 0.814435, 0.825814, 0.820059, \n",
        "               0.820981, 0.819906, 0.834162, 0.837852, 0.835027, 0.842921, 0.84883, 0.853307, 0.855639, 0.857455, \n",
        "               0.860958, 0.865396, 0.864806, 0.867825, 0.834639, 0.811821, 0.831888, 0.816515, 0.838149, 0.842964]\n",
        "psnr_scores = [23.080706, 23.45738, 25.606309, 25.76544, 26.653386, 18.444387, 23.632753, 23.343533, 25.344902, \n",
        "               25.04543, 25.153869, 25.272871, 25.865402, 26.219113, 25.773821, 26.357748, 26.629119, 26.837197, \n",
        "               26.887446, 26.915344, 26.942715, 27.363051, 27.193375, 26.941089, 23.492196, 24.268306, 25.700318, \n",
        "               25.134393, 26.099779, 26.237189]\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# SSIM Plot\n",
        "ax1.plot(epochs, ssim_scores, marker='o', color='tab:blue')\n",
        "ax1.set_title('SSIM Scores over Epochs')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('SSIM Score')\n",
        "ax1.grid(True)\n",
        "\n",
        "# PSNR Plot\n",
        "ax2.plot(epochs, psnr_scores, marker='o', color='tab:orange')\n",
        "ax2.set_title('PSNR Scores over Epochs')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('PSNR Score')\n",
        "ax2.grid(True)\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def get_folder_size(folder):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(folder):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size\n",
        "\n",
        "results_dir = \"/workspace/results/cnn\"\n",
        "folders = [f for f in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, f))]\n",
        "\n",
        "# Ordina le cartelle in ordine alfabetico\n",
        "folders.sort()\n",
        "\n",
        "folder_sizes = {}\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(results_dir, folder)\n",
        "    size_in_mb = get_folder_size(folder_path) / (1024 * 1024)\n",
        "    folder_sizes[folder] = size_in_mb\n",
        "\n",
        "for folder, size in folder_sizes.items():\n",
        "    print(f\"{size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_images_dir = \"/workspace/cnn/nn_datasets/test/images\"\n",
        "\n",
        "def get_folder_size(folder):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(folder):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size\n",
        "\n",
        "test_images_size = get_folder_size(test_images_dir) / (1024 * 1024)  # Convert to MB\n",
        "print(f\"Size of test images folder: {test_images_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compressione con codifica entropica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import zstandard as zstd\n",
        "import pickle\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n",
        "\n",
        "\n",
        "models_dir = 'drive/MyDrive/Colab Notebooks/Colab Notebooks/nn_datasets/checkpoints2'\n",
        "output_dir = 'drive/MyDrive/Colab Notebooks/Colab Notebooks/nn_datasets/results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def extract_encoder(model):\n",
        "    encoder_layers = ['input_layer', 'conv2d', 'max_pooling2d', 'conv2d_1', 'max_pooling2d_1', 'conv2d_2', 'max_pooling2d_2', 'conv2d_3', 'conv2d_4']\n",
        "    encoder = Model(inputs=model.input, outputs=model.get_layer(encoder_layers[-1]).output)\n",
        "    return encoder\n",
        "\n",
        "def process_images(encoder, output_dir, epoch):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    c = 0\n",
        "    total_encoded = []\n",
        "\n",
        "    start_save_time = time.time()\n",
        "    while c < 67:\n",
        "        batch = next(test_generator)\n",
        "        latent_representations = encoder.predict(batch[0],  verbose=0)\n",
        "        total_encoded.append(latent_representations)\n",
        "        c += 1\n",
        "\n",
        "    with open(os.path.join(output_dir, f'total_encoded_{epoch}.pkl'), 'wb') as f:\n",
        "        pickle.dump(total_encoded, f)\n",
        "\n",
        "    end_save_time = time.time()\n",
        "    save_time = end_save_time - start_save_time\n",
        "    uncompressed_size = os.path.getsize(os.path.join(output_dir, f'total_encoded_{epoch}.pkl'))\n",
        "    print(f\"Uncompressed size for epoch {epoch}: {round(uncompressed_size / 1024, 2)} KB\")\n",
        "    print(f\"Time taken to save the uncompressed data: {save_time:.2f} seconds\")\n",
        "\n",
        "    start_compress_time = time.time()\n",
        "    with open(os.path.join(output_dir, f\"total_encoded_{epoch}.pkl\"), \"rb\") as f_in, \\\n",
        "         open(os.path.join(output_dir, f\"total_encoded_{epoch}.pkl.zst\"), \"wb\") as f_out:\n",
        "        cctx = zstd.ZstdCompressor(level = 22)\n",
        "        f_out.write(cctx.compress(f_in.read()))\n",
        "\n",
        "    end_compress_time = time.time()\n",
        "    compress_time = end_compress_time - start_compress_time\n",
        "    compressed_size = os.path.getsize(os.path.join(output_dir, f\"total_encoded_{epoch}.pkl.zst\"))\n",
        "    print(f\"Compressed size for epoch {epoch}: {round(compressed_size / 1024, 2)} KB\")\n",
        "    print(f\"Time taken to compress the data with Zstandard: {compress_time:.2f} seconds\")\n",
        "\n",
        "    total_time = save_time + compress_time\n",
        "    print(f\"Total time for epoch {epoch} (save + compression): {total_time:.2f} seconds\")\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    model_path = os.path.join(models_dir, f'autoencoder_epoch_{epoch:02d}.h5')\n",
        "    encoder_path = os.path.join(models_dir, f'encoder_epoch_{epoch:02d}.h5')\n",
        "    model_output_dir = os.path.join(output_dir, f'epoch_{epoch:02d}')\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        model = load_model(model_path)\n",
        "        encoder = extract_encoder(model)\n",
        "        encoder.save(encoder_path)\n",
        "        print(f\"Encoder for epoch {epoch} saved.\")\n",
        "        process_images(encoder, model_output_dir, epoch)\n",
        "    else:\n",
        "        print(f'Model for epoch {epoch} not found.')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "data_compression",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
