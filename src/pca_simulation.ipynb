{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, pickle, subprocess, re, numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica e restituisce un np.array contenente tutti i frame connessi\n",
    "def load_frames(input_path):\n",
    "    all_files = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]\n",
    "\n",
    "    frames = []\n",
    "    for frame_file in all_files:\n",
    "        frame_path = os.path.join(input_path, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame.flatten())  \n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "# Train and return pca model trained on data\n",
    "def train_pca_model(frames, n_components):\n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(frames)\n",
    "    return pca\n",
    "\n",
    "# Compress and save data\n",
    "def apply_pca(pca_model, frames, original_shape, names):\n",
    "    compressed_frames = pca_model.transform(frames)\n",
    "    serialize_pca(original_shape, compressed_frames, names, '../results/PCA/')\n",
    "    \n",
    "# Serialize data into bytes file\n",
    "def serialize_pca(original_shape, compressed_data, frame_names, output_path):\n",
    "    data_to_save = {\n",
    "        'compressed_data': compressed_data,\n",
    "        'original_shape': original_shape,\n",
    "        'frame_names': frame_names,\n",
    "    }\n",
    "    with open(output_path + 'compressed_data.pkl', 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "        \n",
    "# Deserialize data into orginal format\n",
    "def deserialize_pca(input_path):\n",
    "    with open(input_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['compressed_data'], data['original_shape'], data['frame_names']\n",
    "\n",
    "# Load received frames and save\n",
    "def transform_and_save(pca_object, frames, original_shape, frame_names):\n",
    "    reconstructed_frames = pca_object.inverse_transform(frames)\n",
    "    \n",
    "    os.makedirs(\"../results/PCA/decoder_output/\", exist_ok = True)\n",
    "    \n",
    "    for i, frame in enumerate(reconstructed_frames):\n",
    "        frame_reshaped = frame.reshape(original_shape).astype(np.uint8) \n",
    "        save_path = os.path.join(\"../results/PCA/decoder_output/\", frame_names[i])\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(frame_reshaped, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "\n",
    "def split_data(dataset_name):\n",
    "    # Percorso della cartella con le immagini\n",
    "    base_folder = \"../datasets/\"\n",
    "\n",
    "    # Destinazioni per train e test\n",
    "    train_folder = \"../pca_datasets/train/\" + dataset_name + \"/\"\n",
    "    test_folder = \"../pca_datasets/test/\" + dataset_name + \"/\"\n",
    "\n",
    "    # Crea le cartelle di destinazione\n",
    "    os.makedirs(train_folder, exist_ok = True)\n",
    "    os.makedirs(test_folder, exist_ok = True)\n",
    "\n",
    "    # Lista delle immagini\n",
    "    images = [f for f in os.listdir(base_folder + dataset_name) if os.path.isfile(os.path.join(base_folder + dataset_name, f))]\n",
    "\n",
    "    # Shuffle delle immagini\n",
    "    random.seed(42)  # Per riproducibilit√†\n",
    "    random.shuffle(images)\n",
    "\n",
    "    split_index = int(0.7 * len(images))\n",
    "\n",
    "    train_images = images[:split_index]\n",
    "    test_images = images[split_index:]\n",
    "\n",
    "    # Sposta i file\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(base_folder + dataset_name, img), os.path.join(train_folder, img))\n",
    "\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(base_folder + dataset_name, img), os.path.join(test_folder, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"ArtGallery\", \"Blob\", \"Car\", \"Cobblestone\", \"Dice\", \"Dragons\", \"Fish\", \"Mannequin\", \"Messerschmitt\"]\n",
    "for name in names:\n",
    "    split_data(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder simulation\n",
    "\n",
    "dataset_name = \"Messerschmitt\"\n",
    "n_components = 60\n",
    "train_input_path = \"../pca_datasets/train/\" + dataset_name + \"/\"\n",
    "\n",
    "compact_frames = load_frames(train_input_path)\n",
    "\n",
    "all_files = [f for f in os.listdir(train_input_path) if os.path.isfile(os.path.join(train_input_path, f))]\n",
    "sample_frame = cv2.imread(os.path.join(train_input_path, all_files[0]))\n",
    "original_shape = sample_frame.shape\n",
    "\n",
    "pca_object = train_pca_model(compact_frames, n_components)\n",
    "\n",
    "test_input_path = \"../pca_datasets/test/\" + dataset_name + \"/\"\n",
    "test_names = [f for f in os.listdir(test_input_path) if os.path.isfile(os.path.join(test_input_path, f))]\n",
    "test_frames = load_frames(test_input_path)\n",
    "\n",
    "apply_pca(pca_object, test_frames, original_shape, test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder simulation\n",
    "\n",
    "dataset_name = \"Messerschmitt\"\n",
    "input_path = \"../pca_datasets/test/\" + dataset_name + \"/\"\n",
    "output_path = \"../results/PCA/\" + dataset_name + \"/\"\n",
    "\n",
    "frames_compressed, original_shape, names = deserialize_pca('../results/PCA/compressed_data.pkl')\n",
    "transform_and_save(pca_object, frames_compressed, original_shape, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(decompressed_path, original_path):  \n",
    "    # Esegui il comando per calcolare SSIM usando ffmpeg\n",
    "    ssim_result = subprocess.run(\n",
    "        [\"../../bin/ffmpeg\", \"-i\", decompressed_path, \"-i\", original_path, \"-lavfi\", \"ssim=stats_file=ssim_logfile.txt\", \"-f\", \"null\", \"-\"],\n",
    "        capture_output = True, text = True\n",
    "    )\n",
    "    \n",
    "    # Esegui il comando per calcolare PSNR usando ffmpeg\n",
    "    psnr_result = subprocess.run(\n",
    "        [\"../../bin/ffmpeg\", \"-i\", decompressed_path, \"-i\", original_path, \"-lavfi\", \"psnr=stats_file=psnr_logfile.txt\", \"-f\", \"null\", \"-\"],\n",
    "        capture_output = True, text = True\n",
    "    )\n",
    "    \n",
    "    # Estrai il valore SSIM dal log\n",
    "    ssim_match = re.search(r\"All:([\\d.]+)\", ssim_result.stderr)\n",
    "    ssim = float(ssim_match.group(1)) if ssim_match else None\n",
    "\n",
    "    # Estrai il valore PSNR medio dal log\n",
    "    psnr_match = re.search(r\"average:([\\d.]+)\", psnr_result.stderr)\n",
    "    #print(psnr_result.stderr)\n",
    "    psnr = float(psnr_match.group(1)) if psnr_match else None\n",
    "    \n",
    "    return ssim, psnr\n",
    "\n",
    "\n",
    "def plot_metrics(ssim_values, psnr_values, execution_times, compressed_sizes, pca_components):\n",
    "    psnr_values = [0 if x is None else x for x in psnr_values]\n",
    "\n",
    "    plt.figure(figsize=(12, 16))\n",
    "\n",
    "    def annotate_values(x, y, ax):\n",
    "        for i, val in enumerate(y):\n",
    "            ax.text(x[i], y[i], f\"{val:.2f}\", fontsize=10, color=\"black\", ha=\"right\", va=\"bottom\")\n",
    "\n",
    "    # Grafico SSIM\n",
    "    ax1 = plt.subplot(4, 1, 1)\n",
    "    ax1.plot(pca_components, ssim_values, marker='o', color='blue', label='SSIM')\n",
    "    plt.xticks(pca_components)\n",
    "    plt.title(\"SSIM in base al numero di componenti PCA\", fontsize=14)\n",
    "    plt.xlabel(\"Numero di componenti PCA\", fontsize=12)\n",
    "    plt.ylabel(\"SSIM\", fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(fontsize=12)\n",
    "    annotate_values(pca_components, ssim_values, ax1)\n",
    "\n",
    "    # Grafico PSNR\n",
    "    ax2 = plt.subplot(4, 1, 2)\n",
    "    ax2.plot(pca_components, psnr_values, marker='s', color='orange', label='PSNR')\n",
    "    plt.xticks(pca_components)\n",
    "    plt.title(\"PSNR in base al numero di componenti PCA\", fontsize=14)\n",
    "    plt.xlabel(\"Numero di componenti PCA\", fontsize=12)\n",
    "    plt.ylabel(\"PSNR (dB)\", fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(fontsize=12)\n",
    "    annotate_values(pca_components, psnr_values, ax2)\n",
    "\n",
    "    # Grafico Tempo di Esecuzione\n",
    "    ax3 = plt.subplot(4, 1, 3)\n",
    "    ax3.plot(pca_components, execution_times, marker='^', color='green', label='Tempo di Esecuzione')\n",
    "    plt.xticks(pca_components)\n",
    "    plt.title(\"Tempo di esecuzione in base al numero di componenti PCA\", fontsize=14)\n",
    "    plt.xlabel(\"Numero di componenti PCA\", fontsize=12)\n",
    "    plt.ylabel(\"Tempo di esecuzione (s)\", fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(fontsize=12)\n",
    "    annotate_values(pca_components, execution_times, ax3)\n",
    "\n",
    "    # Grafico Dimensione del File Compresso\n",
    "    ax4 = plt.subplot(4, 1, 4)\n",
    "    ax4.plot(pca_components, compressed_sizes, marker='v', color='purple', label='Dimensione del File Compresso')\n",
    "    plt.xticks(pca_components)\n",
    "    plt.title(\"Dimensione del file compresso in base al numero di componenti PCA\", fontsize=14)\n",
    "    plt.xlabel(\"Numero di componenti PCA\", fontsize=12)\n",
    "    plt.ylabel(\"Dimensione (KB)\", fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(fontsize=12)\n",
    "    annotate_values(pca_components, compressed_sizes, ax4)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"metrics_vs_pca_components_with_values.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "\n",
    "dataset_name = \"\"\n",
    "train_input_path = \"../pca_datasets/train/\" + dataset_name + \"/\"\n",
    "\n",
    "number_of_files = len([f for f in os.listdir(train_input_path) if os.path.isfile(os.path.join(train_input_path, f))])\n",
    "components_range = [round(x) for x in np.linspace(1, number_of_files, 8)]\n",
    "components_range = components_range[:-1]\n",
    "\n",
    "\n",
    "ssim_scores, psnr_scores, execution_times, sizes = [], [], [], []\n",
    "for n_components in components_range:\n",
    "        print(f\"Testing PCA compression with {n_components} components...\")\n",
    "        \n",
    "        # Simulate encoder\n",
    "        start_time = time.time()\n",
    "        compact_frames = load_frames(train_input_path)\n",
    "\n",
    "        all_files = [f for f in os.listdir(train_input_path) if os.path.isfile(os.path.join(train_input_path, f))]\n",
    "        sample_frame = cv2.imread(os.path.join(train_input_path, all_files[0]))\n",
    "        original_shape = sample_frame.shape\n",
    "\n",
    "        pca_object = train_pca_model(compact_frames, n_components)\n",
    "\n",
    "        test_input_path = \"../pca_datasets/test/\" + dataset_name + \"/\"\n",
    "        test_names = [f for f in os.listdir(test_input_path) if os.path.isfile(os.path.join(test_input_path, f))]\n",
    "        test_frames = load_frames(test_input_path)\n",
    "\n",
    "        apply_pca(pca_object, test_frames, original_shape, test_names)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        \n",
    "        execution_times.append(end_time - start_time)\n",
    "        sizes.append(os.path.getsize(\"/workspace/results/PCA/compressed_data.pkl\") / 1024)\n",
    "\n",
    "        print(f\"Execution time with {n_components} components: {execution_times}\")\n",
    "\n",
    "        # Simulate decoder\n",
    "        frames_compressed, original_shape, names = deserialize_pca('../results/PCA/compressed_data.pkl')\n",
    "        transform_and_save(pca_object, frames_compressed, original_shape, names)\n",
    "    \n",
    "        # Calcola SSIM e PSNR\n",
    "        ssim, psnr = calculate_metrics(\"/workspace/results/PCA/decoder_output/\" + names[0], \"/workspace/pca_datasets/test/\" + dataset_name + \"/\" + names[0])\n",
    "        ssim_scores.append(ssim)\n",
    "        psnr_scores.append(psnr)\n",
    "        print(f\"SSIM: {ssim}, PSNR: {psnr} with {n_components} components\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "plot_metrics(ssim_scores, psnr_scores, execution_times, sizes, components_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
